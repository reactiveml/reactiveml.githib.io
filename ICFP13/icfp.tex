%\documentclass{llncs}
\documentclass[9pt,preprint]{sigplanconf}
%\documentclass[a4paper]{article}
%\usepackage[utf8]{inputenc}
%\usepackage{lmodern}
\usepackage[T1]{fontenc}
%\usepackage[style=alphabetic]{biblatex}
%\usepackage{csquotes}
\usepackage[english]{babel}
\usepackage{url}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{amsmath,amsfonts,amssymb,amsthm}
\usepackage{mathpartir}
\usepackage{listings}
%\usepackage{cprotect} % for listings in footnotes
\usepackage{pgf}
\usepackage[colorlinks,
            linkcolor=black,
            citecolor=black,
            urlcolor=black]{hyperref}
%\usepackage{array}
%\usepackage{multirow}

%% Pour avoir la police tt ligt en lmodern
%\DeclareFontFamily{T1}{lmtt}{} \DeclareFontShape{T1}{lmtt}{m}{n}{<-> ec-lmtl10}{} \DeclareFontShape{T1}{lmtt}{m}{\itdefault}{<-> ec-lmtlo10}{} \DeclareFontShape{T1}{lmtt}{\bfdefault}{n}{<-> ec-lmtk10}{} \DeclareFontShape{T1}{lmtt}{\bfdefault}{\itdefault}{<-> ec-lmtko10}{}

\usepackage[caption=false]{subfig} % sigplanconf complains without caption=false
\usepackage{rml}
%\usepackage{graphicx}


%\renewcommand{\ttdefault}{pcr}
%\usepackage{beramono}
%\usepackage{bold-extra}
\renewcommand{\ttdefault}{txtt}

\input{syntax}

\bibliographystyle{plain}

\newcommand{\todo}[1]{ {\color{red} #1}}

%\newcommand{\deq}{\stackrel{\text{\tiny def}}{=}}
\newcommand{\deq}{\triangleq}
\newcommand{\sdeq}{::=}
\newcommand\rulename[1]{\text{(\textsc{#1})\;} }



\begin{document}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{property}{Property}
\newtheorem{lemma}{Lemma}
\newtheorem{hypothesis}{Hypothesis}

\theoremstyle{definition}
\newtheorem{definition}{Definition}

\title{Reactivity of Cooperative Systems}
%\thanks{This work is supported by the INRIA Action d'envergure Synchronics.}
\subtitle{Application to \rml}

\authorinfo{ %\vspace*{-.5cm}
           Louis Mandel}
{LRI, Universit\'e Paris-Sud 11, Orsay, France}
{louis.mandel@lri.fr}

\authorinfo{C\'edric Pasteur}
{DI, \'Ecole normale sup\'erieure, Paris, France}
{cedric.pasteur@ens.fr}

\maketitle

\begin{abstract}
Cooperative scheduling enables efficient sequential implementation of concurrency. It is widely used to provide light threads facilities. However, it is up to the programmer to actually cooperate to ensure the reactivity of the program. 

We present a static analysis that checks the reactivity of programs by abstracting them into so-called \emph{behaviors} using a type-and-effect system. Our work is applied and implemented in the functional synchronous language \rml. We prove the soundness of our analysis with respect to the big-step semantics: a well-typed program is reactive. \todo{Consequences}
\end{abstract}

\category{D.3.2}{Language Classifications}{Applicative (functional) languages; Concurrent, distributed, and parallel languages}
\category{D.3.4}{Processors}{Compilers}
%\category{F.3.2}{Semantics of Programming Languages}{Operational semantics}

\terms
Languages, Theory

\keywords
Synchronous languages; Functional languages;  Semantics; Type systems; Cooperative scheduling

\section{Introduction}
\label{sec:introduction}

%\begin{itemize}
%\item Cooperative scheduling: enables lightweight threads, create thousands, millions of threads. Impossible with OS threads. Synchronization almost for free. Available in all languages (asynchronous computations~\cite{Syme:2011} in \fsharp, \conhaskell~\cite{Jones:1996}, \lwt~\cite{Vouillon:2008} for \ocaml), implementation easy with continuations (see \cite{Claessen:1999})
%\item Idea: Each thread cooperates with the scheduler at some point to let other processes execute
%\item Two problems:
%\begin{itemize}
%\item The programmer has to cooperate at some point. In particular in infinite loop that are characteristic of reactive and interactive systems: at each occurence of this event, do that; forever do that
%\item Cannot call blocking functions, in particluar OS primitives for I/O
%\end{itemize}

Most functional languages offer light-thread facilities, either integrated in the language like the asynchronous computations~\cite{Syme:2011} in \fsharp, or available as a library like \conhaskell~\cite{Jones:1996} or \lwt~\cite{Vouillon:2008} for \ocaml. These libraries are based on cooperative scheduling: each thread of execution cooperates with the scheduler to let other threads execute. This enables an efficient and sequential implementation of concurrency, allowing to create up to millions of separate threads, which is impossible with operating system threads. Synchronization also comes almost for free, without requiring any synchronization primitive like locks. The functional paradigm makes the implementation even easier, by using \emph{continuations}~\cite{Claessen:1999}.

The downside of cooperative scheduling is that it is necessary to make sure that threads actually cooperate:
\begin{itemize}
\item The programmer has to return control to the scheduler regularly. This is particularly true for infinite loops, that are very often present in \emph{reactive} and \emph{interactive} systems~\cite{Harel:1985}. 
\item She cannot call blocking functions like operating system primitives for I/O. 
\end{itemize}

%\item Solution to the latter: never use these functions. Libraries implement cooperative alternatives, use them instead. See \cite{Marlow:2004} for an overview on how to implement these blocking operations safely.

The solution to the latter is pretty simple: never use blocking functions inside cooperative threads. All the facilities mentioned earlier provide either I/O libraries compatible with cooperative scheduling or means to safely call blocking functions. See \cite{Marlow:2004} for an overview on how to implement blocking operations safely in this context.

%\item In this paper we tackle the first issue: not forget to cooperate with the scheduler.
%\item Analysis applied to the \rml language~\cite{Mandel:2005}: a reactive extension of ML, i.e. ML with a synchronous model of concurrency~\cite{Benveniste:2003}. Divide the execution in logical time steps. Communication and computations instantaneous. Deterministic concurrency. Advantage of \rml for reactivity analysis:
%\begin{itemize}
%\item Concurrency exposed at the level of language, so easier to implement an analysis
%\item Synchrony gives a simple meaning to reactivity: a program is reactive if logical instants progress. So a program is reactive if all process cooperate at each instant. The analysis could be applied to other concurrency model, but require some hypothesis of fairness from the scheduler. Synchrony is Very strong fairness hypothesis: processes execute in lock-step.
%\end{itemize}

The goal of this paper is to design a static analysis, called \emph{reactivity analysis}, to remedy the first problem. The analysis checks that the programmer does not forget to cooperate with the scheduler.
%
Our work is applied on the \rml language~\cite{Mandel:2005}, which is an extension of ML with a synchronous model of concurrency~\cite{Benveniste:2003}. Section~\ref{sec:problem} informally introduces the language and its semantics. The idea of synchronous languages is to divide the execution of a program into discrete logical instants, where computations and communications are considered instantaneous. This results in a deterministic model of concurrency that is compatible with the dynamic creation of processes~\cite{Boussinot:1991}.  Synchrony gives us a simple definition for reactivity: a reactive \rml program is one where logical instants progress. It also gives us a simple condition for reactivity: a program is reactive if all processes cooperate at each instant. Doing a similar analysis with another model of concurrency would require assumptions on the fairness of the scheduler. %(\todo{Synchrony is actually a very strong fairness hypothesis: processes execute in lock-step ??})



%Contributions of the paper:
%\begin{itemize}
%\item A reactivity analysis implemented as a type-and-effect system~\cite{Lucassen:1988}
%\item A new approach to subeffecting~\cite{Nielson:1999}, i.e replacing an effect with a less precise one, using row polymorphism~\cite{Remy:1993}
%\item The proof of soundness of the analysis
%\end{itemize}

The contributions of this paper are the following:
\begin{itemize}
\item A reactivity analysis presented as a type-and-effect system~\cite{Lucassen:1988} in Section~\ref{sec:type_system}. The computed effects are called \emph{behaviors}~\cite{Amtoft:1999} and are introduced in Section~\ref{sec:behaviors}. They represent the reactive behaviors of processes, by abstracting away values but keeping some part of the structure of the program. Exposing concurrency in the language makes it possible to express the analysis easily, which would not have been the case if concurrency had been implemented as a library.
\item A novel approach to \emph{subeffecting}~\cite{Nielson:1999}, that is, subtyping on effects, based on row polymorphism~\cite{Remy:1993} in Section~\ref{sec:subeffecting_row}.
\item A proof of the soundness of the analysis (Section~\ref{sec:soundness}) with respect to the big-step semantics of \rml (Section~\ref{sec:semantics}): \emph{a well-typed program is reactive}.
\end{itemize}

The paper ends with some discussion and examples~(Section~\ref{sec:discussion}) and related work~(Section~\ref{sec:related_work}). The work presented here is implemented in the \rml compiler.\footnote{It is available at \url{http://reactiveml.org}}

\clearpage

\section{Problem statement}
\label{sec:problem}

Let us first introduce \rml{} syntax and informal semantics using a simple program that highlights the problem of non-reactivity.\footnote{This example is taken from an email sent by a \rml programmer asking for help. It motivated the reflexion that lead to this work.} Then we will discuss the design choices and limitations of our reactivity analysis using a few other examples.

\subsection{A first example}
\label{sec:first_example}

We start by creating a process that emits a signal every `timer` seconds:
%
\begin{rmlcl}
let process clock timer s =
  let time = ref (Unix.gettimeofday ()) in
  loop
    let time' = Unix.gettimeofday () in
    if time' -. !time >= timer
    then (emit s (); time := time')
  end
\end{rmlcl}
%
In \rml, there is a distinction between regular ML functions and \emph{processes}, that is, functions whose execution can span several logical instants.  They are defined using the `process` keyword. The `clock`~process is parametrized by a float~`timer` and a signal~`s`. Signals are communication channels between processes, with instantaneous broadcast. The process starts by initializing a local reference `time` with the current time~(line 2), read using the `gettimeofday` function of the `Unix`~module from the standard library. Then it enters an infinite loop~(line 3 to 7). At each iteration, it reads the new current time and emits the unit value on the signal~`s` if enough time has elapsed~(line 6). The compiler prints the following warning when compiling this process:
\begin{lstlisting}
?Line 3, characters 2-120:
W: This expression may be an instantaneous loop?
\end{lstlisting}
The problem is that the body of the loop is instantaneous. It means that this process never cooperates, so that logical instants do not progress. To solve this problem, the programmer must explicitly cooperate by calling the `pause` operator~(line~7), which awaits the next instant, at the end of the loop:
\begin{rmlcl}[5]
[...]
    then (emit s (); time := time');
    pause 
  end
\end{rmlcl}

The second part of the program is a process that prints \verb+`top'+ every time a signal `s` is emitted. 
The `do/when` construct executes its body only when the signal `s` is present (i.e. it is emitted). It terminates by returning the value of its body instantaneously after the termination of the body. Processes have a consistent view of a signal during an instant. It is either present or absent and its status cannot change during the instant.
%
\begin{rmlcl}[10]
let process print_clock s =
  loop
    do
      print_string "top"; print_newline ()
    when s done
  end
\end{rmlcl}
\begin{lstlisting}
?Line 11, characters 2-78:?
?W: This expression may be an instantaneous loop?
\end{lstlisting}
%
Once again, this loop can be instantaneous, but this time it depends on the presence of the signal. While the signal `s` is absent, the process cooperates. When it is present, the body of the `do/when` executes and terminates instantaneously. So the body of the loop also terminates instantaneously, and a new iteration of the loop is started in the same logical instant. Since the signal is still present, the body of the `do/when` executes one more time, and so on. This process can also be fixed by a call to `pause`.

We can then put these two processes in parallel, after declaring a local signal `s`. The result is a program that prints \verb+`top'+ every second:
\begin{rmlcl}[18]
let process main =
  signal s default () gather (fun () () -> ()) in
  run (print_clock s) || run (clock 1. s)
\end{rmlcl}
The declaration of a signal takes as arguments the default value of the signal and a combination function that is used to compute the value of the signal in case of multiple emissions during the same instant. Here, the default value is `()` and the signal keeps this value in case of multi-emission. The `||` operator represents the synchronous parallel composition. Both branches are executed at each instant and communicate through the local signal `s`.

\subsection{Intuitions and limitations}
\label{sec:intuition}

In the previous example, we have seen the first cause of non-reactivity, that is, instantaneous loops. The second one is instantaneous recursive processes, as in this example:
\begin{lstlisting}
let rec process instantaneous s =
  emit s ();
  run (instantaneous s)
?W: This expression may produce an instantaneous recursion?
\end{lstlisting}

A sufficient condition to ensure that a recursive process is reactive is to have \emph{at least one instant between the instantiation of the process and any recursive call}. The idea of our analysis is to statically check this condition.

This condition is very strong and rejects interesting programs that are reactive. For instance, the execution of a parallel `map` is rejected (the `let/and` construct executes its two branches in parallel):
\begin{lstlisting}
let rec process par_map p l =
  match l with
  | [] -> []
  | x :: l -> let x' = run (p x)
              and l' = run (par_map p l) in
              x' :: l'
?W: This expression may produce an instantaneous recursion?
\end{lstlisting}
This process does instantaneous recursive calls, but it is reactive because the recursion is finite (if the list `l` is finite). As we don't want to prove the termination of such processes, our analysis only prints warnings and does not reject programs.
As ML functions are always considered instantaneous, they are reactive if and only if they terminate. %This is where the syntactic separation between functions and processes helps us: 
We can restrict our analysis to processes and suppose that functions always terminate.
We thus avoid showing a warning for each recursive function.

Furthermore, we do not deal with blocking functions, like I/O primitives, that can also make the program non-reactive. Indeed, such functions should \emph{never} be used in the context of cooperative scheduling. A solution to this problem could be to consider blocking operations as processes and implement them following the ideas in~\cite{Marlow:2004}.

The analysis does not either take into account the presence of signals. It over-approximates the possible behaviors, as in the following example:
\begin{lstlisting}
let rec process imprecise =
  signal s default () gather (fun () () -> ()) in
  present s then () else (* implicit pause *) ();
  run imprecise
?W: This expression may produce an instantaneous recursion?
\end{lstlisting}
%
The `present/then/else` construct executes instantaneously its first branch if the signal is present or executes the second branch with a delay of one instant if the signal is absent. This delayed reaction to absence, first introduced in~\cite{Boussinot:1991}, avoids inconsistencies in the status of signals. In the example, the signal is absent so the `else` branch is executed. It means that the recursion is not instantaneous and the process is reactive. Our analysis still prints a warning, because if the signal `s` could be present, the recursion would be instantaneous.

Finally, we only guarantee that a program will react, not that is is real-time, that is, that it reacts in bounded time, as shown by this example:
\begin{lstlisting}
let rec process server add =
  await add(p, ack) in
  run (server add) || let v = run p in emit ack v
\end{lstlisting}
%
The `server` process receives on a signal `add` both a process `p` and a signal `ack` on which to send back the result. As it creates one new process each time the `add` signal is emitted, this program can execute an arbitrary number of processes at the same time. It is thus not real-time, but it is indeed reactive, as waiting for the value of a signal takes one instant (one has to collect and combine all the values emitted during the instant).

\section{The algebra of behaviors}
\label{sec:behaviors}

\input{derived}

The idea of our analysis is to abstract processes into a simpler language called \emph{behaviors}, following the work of~\cite{Amtoft:1999}. Behaviors abstract the reactive behavior of processes. A main design choice is to completely abstract values and the presence of signals. It is however necessary to keep part of the structure of the program (or an abstraction of it) in order to have a precise analysis.

\subsection{The behaviors}

The algebra of behaviors is given by:
\footnote{The order of precedence of operators is the following (from highest to lowest): $\mathtt{run}$, $;$, $+$, $||$ and finally $\mu$. For instance: \\
$ \effrec{\effvar}{\effpar{\rk_1}{\effor{\effrun{\rk_2}}{\effcon{\effplus}{\rk_3}}}} $
means
$ \effrec{\effvar}{(\effpar{\rk_1}{(\effor{\effrun{(\rk_2)}}{(\effcon{\effplus}{\rk_3})})})} $
}
%
\[
\rk \sdeq \effplus ~\mid~ \effmin ~\mid~ \effvar ~\mid~ \effpar{\rk}{\rk} ~\mid~ \effor{\rk}{\rk}
~\mid~ \effcon{\rk}{\rk}  ~\mid~ \effrec{\effvar}{\rk}  ~\mid~ \effrun{\rk}
\]

Surely non-instantaneous actions that takes at least one instant to execute, such as $\epause$, are denoted $\effplus$. Potentially instantaneous ones, like calling a pure ML function or emitting a signal, are denoted $\effmin$. The language also includes behavior variables $\effvar$ to represent the behaviors of processes taken as arguments. 

Behaviors must reflect the structure of the program, starting with parallel composition. This is illustrated by the following example, which defines a combinator that takes as inputs two processes `q1` and `q2` and runs them in parallel in a loop: 
\begin{lstlisting}
let process par_comb q1 q2 =
  loop (run q1 || run q2) end
\end{lstlisting}
The synchronous parallel composition terminates when both bran\-ches have terminated. It means that the loop is non-instantaneous if either `q1` or `q2` is non-instantaneous.  That is why behaviors include the parallel composition, simply denoted $||$.
%
Similarly, we can define another combinator that runs one of its two inputs depending on a condition `c`:
\begin{lstlisting}
let process if_comb c q1 q2 =
  loop (if c then run q1 else run q2) end
\end{lstlisting}
In the case of `if_comb`, both processes must be non-instantaneous. To represent this process, we use a non-deterministic choice operator denoted $+$. This shows how  we abstract values: we only keep the different alternatives and forget about the conditions.

It is also necessary to have a notion of sequence, denoted~$;$ in the language of behaviors, as illustrated by the two following processes: 
\begin{lstlisting}
let rec process good_rec = 
  pause; run good_rec
  
let rec process bad_rec = 
  run bad_rec; pause
\end{lstlisting}
The order between the recursive call and the call to `pause` is crucial as the `good_rec` process is reactive while `bad_rec` loops instantaneously.
%
As it is defined recursively, the behavior  $\rk$  associated to the `good_rec` process must verify that~\mbox{$ \rk = \effcon{\effplus}{\effrun{\rk}}$}. The $\mathtt{run}$ operator is associated to running a process and is necessary to solve technical problems in the type system, that will be discussed in Section~\ref{sec:run}. This equation can be solved by introducing an explicit recursion operator $\mu$ so that $\rk = \effrec{\effvar}{\effcon{\effplus}{\effrun{\effvar}}}$. Recursive behaviors verify the usual property:
\begin{mathpar}
\effrec{\effvar}{\rk} = \rk[\effvar \leftarrow \effrec{\effvar}{\rk}] 
\and
\effrec{\effvar}{\rk} = \rk \text{ if } \effvar \not\in \fbv{\rk}
\end{mathpar}

We denote $\fbv{\rk}$ the set of free behavior variables in $\rk$. It should be noted that there is no operator for representing the behavior of a loop. Indeed, a loop is just a special case of recursion. The behavior of a loop, denoted $\effinf{\rk}$ (where $\rk$ is the behavior of the body of the loop), is thus defined as a recursive behavior by:
\[\effinf{\rk} \deq \effrec{\effvar}{\effcon{\rk}{\effrun{\effvar}}} \]

%\begin{figure}[t]
%
%\subfloat[Reactive behaviors]{
%\begin{small}
%\input{wf}
%\end{small}
%\label{fig:reactive_behavior}
%}
%
%\subfloat[Non-instantaneous behaviors]{
%\begin{small}
%\input{noinst}
%\end{small}
%\label{fig:noinst_behavior}
%}
%
%\caption{Properties of behaviors}
%\end{figure}


\subsection{Reactive behaviors}
\label{sec:reactive_behavior}

Using the language of behaviors, we can now characterize the behaviors that we want to reject, that is instantaneous loops and recursions. We actually enforce a stronger sufficient condition, that can be checked easily and efficiently: there must be at least one instant before each recursive call. This condition is not necessary, as the `par_map` example of Section~\ref{sec:intuition} showed. One can also check from the definition of $\effinf{\rk}$ as a recursive behavior that this condition also implies that the body of a loop is non-instantaneous.

To formally define what is a reactive behavior, we thus have to define the notion of \emph{non-instantaneous} behavior:
\begin{definition}[Non-instantaneous behavior]
A behavior is \emph{non-instantaneous}, denoted $\noinst{\rk}$, if:
%\begin{small}
\input{noinst}
%\end{small}
\end{definition}
The fact that variables are considered non-instantaneous means that any process taken as argument is supposed to be non-instantan\-eous. If this is not the case, then the verification of reactivity is done when this variable is instantiated with the actual behavior of the process.

A behavior is said to be \emph{reactive}  if for each recursive behavior $\effrec{\effvar}{\rk}$, the recursion variable~$\effvar$ does not appear in the first instant of the body $\rk$. 
\begin{definition}[Reactive behavior]
\label{def:reactive_behavior}
A behavior $\rk$ is \emph{reactive} if $\wf{\emptyset}{\rk}$, where the relation $\wf{R}{\rk}$ is defined by:
%\begin{small}
\input{wf}
%\end{small}
\end{definition}
The predicate \mbox{$\wf{R}{\rk}$} means that the behavior $\rk$ is reactive with respect to the set of variables $R$, that is, these variables do not appear in the first instant of $\rk$ and all the recursions inside $\rk$ are not instantaneous. 
In the case of the sequence $\eseq{\rk_1}{\rk_2}$ , if the behavior $\rk_1$ is non-instantaneous, then it is not necessary to check if the variables in $R$ appear free in $\rk_2$. However, we still have to check that $\rk_2$ is reactive, that is, that $\wf{\emptyset}{\rk_2}$.

%
%%
%%\begin{small}
%\input{wf}
%%\end{small}
%%
%The rule for the sequence $\eseq{\rk_1}{\rk_2}$ uses the notion of \emph{non-instantaneous} behavior, denoted $\noinst{\rk}$ and defined below. Indeed, if the behavior $\rk_1$ is non-instantaneous, then it is not necessary to check if the variables in $R$ appear free in $\rk_2$. However, we still have to check that $\rk_2$ is reactive, that is, that $\wf{\emptyset}{\rk_2}$.
%%
%%\begin{small}
%\input{noinst}
%%\end{small}
%%
%The fact that variables are considered non-instantaneous means that any process taken as argument is supposed to be non-instantan\-eous. If this is not the case, then the verification of reactivity is done when this variable is instantiated with the actual behavior of the process.

\begin{figure*}[t]
%\begin{small}
\input{rules}
%\end{small}

\caption{Type-and-effect rules}
\label{fig:rules}
\end{figure*}

\subsection{Equivalence on behaviors}
\label{sec:equiv_behaviors}

We can define an equivalence relation~$\effeq{}{}$ on behaviors. An important property of this relation is that it preserves reactivity, which is expressed by the following property:
\begin{property}
\label{prop:equiv_reactivty}
if $\effeq{\rk_1}{\rk_2}$ and $\wf{R}{\rk_1}$ then $\wf{R}{\rk_2}$
\end{property}

The~$\effeq{}{}$~relation is an equivalence relation, i.e. it is reflexive, symmetric and transitive. The operators $\effcon{}{}$ and $\effpar{}{}$ and $\effor{}{}$ are compatible with this relation, idempotent and associative. $\effpar{}{}$~and $\effor{}{}$ are commutative (but not $;\,$). The~$\effmin$~behavior~(resp.~$\effplus$) is the neutral element of $\effcon{}{}$ and $\effpar{}{}$ (resp.~$\effor{}{}$). The equivalence relation also verifies the following properties:
%
\begin{mathpar}
\inferrule
  { \effeq{\rk_1}{\rk_2} }
  { \effeq{\effrec{\effvar}{\rk_1}}{\effrec{\effvar}{\rk_2}} }
%
\and
%
\inferrule
  { \effeq{\rk_1}{\rk_2} }
  { \effeq{\effrun{\rk_1}}{\effrun{\rk_2}} }
%
\and
%
%\effeq{\effrec{\effvar}{\rk}}{\rk[\effvar \leftarrow \effrec{\effvar}{\rk}]}
%
%\and
%
\effeq{\effinf{\effplus}}{\effplus}
%\and
%\effeq{\effrun{\effmin}}{\effmin}
%\and
%\effeq{\effrun{\effplus}}{\effplus}
\end{mathpar}

For instance, it is easy to show that:
\[
\effeq
 { \effrec{\effvar}{(\effcon{(\effpar{\effplus}{\effmin})}{(\effor{\effrun{\effvar}}{\effrun{\effvar}})})} }
 { \effrec{\effvar}{\effcon{\effplus}{\effrun{\effvar}}} }
\]

\section{The type-and-effect system}
\label{sec:type_system}

The link between processes and behaviors is done by a type-and-effect system~\cite{Lucassen:1988}. The behavior of a process is the effect computed using the type system. A type system is a simple and efficient way to implement a higher-order static analysis.

\subsection{Abstract syntax}

We consider here a kernel of \rml{}:
%
\begin{align*}
v \sdeq &\; c \mid (v, v) \mid n \mid \elam{x}{e} \mid \eproc{e} \\
e \sdeq &\;  x \mid c \mid (e, e) \mid \elam{x}{e} 
  \mid \eapp{e}{e} \mid \erec{x}{e}  \mid \eproc{e} \mid \erun{e} \\
 & \mid \epause{} \mid \eletpar{x}{e}{x}{e}{e} \\
 &\mid \esig{x}{e}{e}{e} \\
 & \mid \eemit{e}{e} \mid \epres{e}{e}{e} \\
 & \mid \eite{e}{e}{e} \\
 &  \mid \eloop{e} \mid \euntil{e}{e}{x}{e} 
   \mid \ewhen{e}{e} 
\end{align*}

Values are constants (integers, booleans, etc.), pairs of values, signal names $n$, functions and processes. The language is a call-by-value lambda-calculus, extended with constructs for creating~($\mathtt{process}$) and running~($\mathtt{run}$) processes, waiting for the next instant~($\mathtt{pause}$), parallel definitions~($\mathtt{let/and}$), declaring signals~($\mathtt{signal}$), emitting a signal~($\mathtt{emit}$) and several control structures: the test of presence of a signal~($\mathtt{present}$), the unconditional loop~($\mathtt{loop}$), weak preemption~($\mathtt{do/until}$) and suspension~($\mathtt{do/when}$).  The expression $\euntil{e_1}{s}{x}{e_2}$ executes its body $e_1$ and, when the signal~$s$ is present, stops the execution of~$e_1$ and then executes the continuation~$e_2$ on the next instant, binding~$x$ to the value of~$s$. We denote $\_$ variables that do not appear free in the body of a $\mathtt{let}$ and $\evoid{}$ the unique value of type $\mathtt{unit}$. From this kernel, we can encode most constructs of the language, as shown in Figure~\ref{fig:derived}.

\subsection{Types}

Types and behaviors are defined by:
\begin{align*}
\rt \sdeq &\;\;\; \rtvar \mid T \mid \rtprod{\rt}{\rt} \mid \rtarrow{\rt}{\rt} \\
    &\;\mid \rtproc{\rt}{\rk} \mid \rtsig{\rt}{\rt} && \text{(types)} \\
\rs \sdeq &\; \rt \mid \forall \effvar.\, \rs \mid \forall \rtvar.\, \rs && \text{(type schemes)} \\
\tyenv \sdeq&\; \emptyset \mid \tyenv \tyconcat x : \rs && \text{(environments)}
\end{align*}
A type is either a type variable $\rtvar$, a base type $T$ (like $\mathtt{bool}$ or $\mathtt{unit}$), a product, a function, a process or a signal. The type of a process is parametrized by its return type and its behavior. The type of a signal is parametrized by the type of emitted values and the type of the read value.

We lift the notion of reactivity and equivalence from behaviors to types. A type is reactive if it contains only reactive behaviors. Two types are equivalent, also denoted $\tyeq{\rt_1}{\rt_2}$, if they have the same structure and their behaviors are equivalent.

Types schemes quantify universally over type variables $\rtvar$ and behavior variables $\effvar$. We denote $\ftv{\rt}$ (resp. $\fbv{\rt}$) the set of type~(resp. behavior) variables free in $\rt$ and:
\[ \fv{\rt} = \ftv{\rt}, \fbv{\rt} \] 
Instantiation and generalization are defined in a classic way:
\begin{mathpar}
\rs[\rtvar \leftarrow \rt] \leq \forall \rtvar.\, \rs 
\and
\rs[\effvar \leftarrow \rk] \leq \forall \effvar.\, \rs  
\end{mathpar}
\vspace{-1.3em}
\begin{align*}
\mathit{gen}(\rt, e, \tyenv) = &\, \rt && \text { if $e$ is expansive} \\
\mathit{gen}(\rt, e, \tyenv) = &\; \forall \bar{\rtvar}.\forall \bar{\effvar}.\; \rt  && \text{ otherwise } \\
  & \text{ where }  \bar{\rtvar}, \bar{\effvar} = \fv{\rt} \setminus \fv{\tyenv}  
\end{align*}
As for references in ML, we have to be careful to not generalize expressions that allocate signals. We use the syntactic criterion of expansive and non-expansive expressions~\cite{Tofte:1990}.

\subsection{Typing rules}

Typing judgments are given by 
\[ \tyju{\tyenv}{e}{\rt}{\rk} \] 
meaning that, in the type environment~$\tyenv$, the expression $e$ has type~$\rt$ and behavior~$\rk$. We write $\tyju{\tyenv}{e}{\rt}{\effany}$ when the behavior of the expression $e$ is not constrained and does not appear in the conclusion of the inference rule. The initial typing environment $\tyenv_0$ is defined by: 
\begin{align*}
\Gamma_0 \deq [
 &\eemit{}{} : \forall  \rtvar_1, \rtvar_2. \, 
        \rtarrow{ \rtsig{\rtvar_1}{\rtvar_2} }{\rtarrow{\rtvar_1}{\unit{}} }; \\
        &\mathtt{true} : \mathtt{bool};
              \mathtt{fst} : \forall \rtvar_1, \rtvar_2.\, \rtarrow{\rtprod{\rtvar_1}{\rtvar_2}}{\rtvar_1};  \ldots ]
\end{align*}

The rules are given in Figure~\ref{fig:rules}. If all the behaviors are erased, it is exactly the same type system as the one presented in~\cite{Mandel:2005}, which is itself an extension of ML type system. We discuss here the novelties of these rules related to behaviors. The rules \textsc{Process} and \textsc{Mask} are related to subeffecting and will be discussed in Section~\ref{sec:subeffecting_row}. 

\begin{itemize}

\item A design choice of \rml{} is to separate pure ML expressions, that are surely instantaneous, from processes. For instance, it is impossible to call $\epause$ within the body of a function, that must be instantaneous. A static analysis done before typing checks this well-formation of expressions, denoted $k \vdash e$ in~\cite{Mandel:2005}. That is why our type system ignores the behavior of expressions that must be ML expressions, like the body of a function. We could prove that their behavior is always equivalent to the instantaneous behavior $\effmin$.

% It should be noted that ML expressions, such that $0 \vdash e$, always verify $\tyju{\tyenv}{e}{\rt}{\effmin}$. This is why many rules enforce the behavior of some expressions to be equal to $\effmin$. This does not add any new condition with respect to the well-formation analysis. The converse is false as the $\effmin$ behavior is associated to \emph{potentially} instantaneous processes whereas $0 \vdash e$ means that $e$ is \emph{necessarily} instantaneous.

\item We do not try to prove the termination of pure ML functions without any reactive behavior: the rule of application shows that we suppose that function calls always terminate instantaneously. That is why there is no behavior associated to functions, that is, there is no behaviors on arrows unlike traditional type-and-effect systems.

\item As explained earlier, in the case of $\epres{e}{e_1}{e_2}$, the first branch $e_1$ is executed immediately if the signal $e$ is present and the second branch $e_2$ is executed at the next instant if it is absent. This is reflected by the behavior associated to the expression. Similarly, for $\euntil{e_1}{e}{x}{e_2}$, $e_2$ is executed at the instant following the presence of $e$.

\item We can also check that the encoding of primitives given in Figure~\ref{fig:derived} yields the expected behaviors. This is for instance the case of $\eseq{e_1}{e_2}$:
%
\par\nobreak\vspace{-2ex}{ \small
\[ 
%\inferrule
%{
\inferrule%*[left=(Equiv)]
  { 
    \inferrule 
      {
        \tyju{\tyenv}{e_1}{\rt_1}{\rk_1} \\
        \tyju{\tyenv}{\evoid}{\unit}{\effmin} \\
        \tyju{\tyenv}{e_2}{\rt_2}{\rk_2} \\
      }
      { 
      \tyju{\tyenv}{\eletpar{\_}{e_1}{\_}{\evoid}{e_2}}{\rt_2}{ \effcon{(\effpar{\rk_1}{\effmin})}{\rk_2} } 
      } 
  }
  { \tyju{\tyenv}{\eseq{e_1}{e_2}}{\rt}{ \effcon{(\effpar{\rk_1}{\effmin})}{\rk_2} } } 
% \\
% \inferrule
%   { \effeq{\effpar{\rk_1}{\effmin}}{\rk_1}  \\ \effeq{\rk_2}{\rk_2} }
%   { \effeq{ \effcon{(\effpar{\rk_1}{\effmin})}{\rk_2} } { \effcon{\rk_1}{\rk_2} } }
%  }
%{
%  \tyju{\tyenv}{\eseq{e_1}{e_2}}{\rt_2}{ \effcon{\rk_1}{\rk_2} }
%}
\]
}%
It is easy to check that $\effeq{ \effcon{(\effpar{\rk_1}{\effmin})}{\rk_2} }{ \effcon{\rk_1}{\rk_2} }$.  We can also check that $\epar{e_1}{e_2}$ has a behavior equivalent to $\effpar{\rk_1}{\rk_2}$ or that $\eawait{e_1}{x}{e_2}$ has a behavior \mbox{$\effeq{\effor{\effinf{\effplus}}{(\effcon{\effplus}{\rk_2})}}{\effcon{\effplus}{\rk_2}}$}. % ou encore que $\eawaitim{e_1}$ a un comportement instantan√© $\effmin$. 

\item In~\cite{Mandel:2005}, the $\mathtt{loop}$ construct is encoded as a recursive process by:
%
\begin{align*}
\eloop{e} \deq &\mathid{run}(( \mathidl{rec} loop = 
     \elam{x}{ \\ &\qquad \eproc{(\eseq{\erun{x}}{\erun{(\eapp{loop}{x})}})}})\; (\eproc{e})) 
\end{align*}
%
By applying the rules here, we have that:
\[ loop: \forall \effvar.\, \rtarrow{\rtproc{\rtvar}{\effvar}}
                { \rtproc{\rtvar'}{\effrec{\effvar'}{\effcon{\effrun{\effvar}}{\effrun{\effvar'}}}}} \]
%

If we suppose that \mbox{$\tyju{\tyenv}{e}{\rt}{\rk}$}, then the behavior of this encoding is: 
  \[ \effrun{(\effrec{\effvar'}{\effcon{\effrun{\rk}}{\effrun{\effvar'}}})} \]
It is not equivalent to $\effinf{\rk}$ in the sense of Section~\ref{sec:equiv_behaviors}, but it is reactive iff $\effinf{\rk}$ is reactive, as the $\mathtt{run}$ operator does not influence reactivity. It means that we could have removed $\mathtt{loop}$ from our kernel without any influence on the result of the reactivity analysis.

\item As for \texttt{loop}, the $\mathtt{pause}$ operator can also be encoded by:
%
\begin{align*}
\mathtt{pause} \deq &\; \esig{s}{\evoid}{(\elam{x}{\elam{y}{\mathtt{\evoid}}})}
                                    { \\ &\qquad \epres{s}{\evoid}{\evoid}}
\end{align*}
%
We have chosen to completely abstract values. As in the `imprecise` example of Section~\ref{sec:intuition}, we do not consider the fact the signal $s$ is always absent, so that only the second branch of the $\mathtt{present}$ is executed. The consequence is that the behavior computed by the type system, that is, $\effeq{\effor{\effmin}{\effcon{\effplus}{\effmin}}}{\effmin}$, is the opposite of the expected behavior of $\epause$.

\end{itemize}

\subsection{Subeffecting with row polymorphism}
\label{sec:subeffecting_row}

\subsubsection*{Subeffecting}

The typing rule for the creation of processes intuitively mean that a process has \emph{at least} the behavior of its body. This subtyping restricted to effects is often referred to as \emph{subeffecting}~\cite{Nielson:1999}: we can always replace an effect with a bigger, i.e. less precise, one. It allows the type system to be a conservative extension of \rml{} type system, that is, we are able to give a behavior to any correct \rml{} program.

Subeffecting~\cite{Talpin:1992a,Nielson:1999} is usually expressed as a non-syntax directed rule (we reuse the notations of our type system for better comparison):
%
\[
\inferrule
  { \tyju{\tyenv}{e}{\rt}{\rk} \\ \rk \sqsubseteq \rk' }
  { \tyju{\tyenv}{e}{\rt}{\rk'}  }
\]
%
The order $\sqsubseteq$ on effects is given by set inclusion when effects are sets~\cite{Talpin:1992a} (of regions for example). In our case, It is defined by:
\begin{mathpar}
\rk_1 \sqsubseteq \effor{\rk_1}{\rk_2}
\and
\rk_2 \sqsubseteq \effor{\rk_1}{\rk_2}
\and
\inferrule{ \effeq{\rk_1}{\rk_2} }{ \rk_1 \sqsubseteq \rk_2 }
\end{mathpar}

A similar approach is used in~\cite{Amtoft:1999}. It enforces effects to be \emph{simple}, that is, effects on arrows are syntactically forced to be variables. A constraint set $C$ is added to the type system to keep track of the relations between variables and effects. Subeffecting is then expressed as:
%
\[
\inferrule
  { \tyju{\tyenv, C}{e}{\rt}{\rk}   }
  {  \tyju{\tyenv, C \cup \{ \rk \sqsubseteq \effvar \} }{ \eproc{e} }{\rtproc{\rt}{\effvar}}{\effmin} }
\]

These three formulations appear to be equivalent. Indeed, our system and the one of~\cite{Amtoft:1999} are just syntax-directed versions of the first one, where the subtyping relation is applied only for lambda abstractions (or processes in our case).

\subsubsection*{Implementing subeffecting with row polymorphism}

The consequence of the typing rule for processes is that the principal type of an expression $\eproc{e}$ is always of the shape $\effor{\rk}{\effvar}$. The idea to use a free type variable to represent other possible types is reminiscent of Remy's row types~\cite{Remy:1993}. It makes it possible to implement subeffecting using only unification, without manipulating constraint sets as in traditional approaches~\cite{Talpin:1992a, Amtoft:1999}. This makes it easier to integrate it in any existing ML type inference implementation. For instance, \ocaml{} type inference is also based on row polymorphism, so it would be easy to implement our analysis on top of the full language. 

During unification, the behavior of a process is always either a behavior variable~$\effvar$, a row~$\effor{\rk}{\effvar}$ or a recursive row~$\effrec{\effvar}{(\effor{\rk}{\effvar'})}$. We could have made this fact more visible by having two different kinds of behaviors: behaviors and rows of behaviors. We chose here to stick with a more simple syntax. We can reuse any existing inference algorithm, like algorithm $\mW$ or $\mM$~\cite{Lee:1998a} and only use the following algorithm $\mU_{\rk}$ for unification of behaviors. It takes as input two behaviors and returns a substitution that maps behavior variables to behaviors, that we denote $[\effvar_1 \mapsto \rk_1; \effvar_2 \mapsto \rk_2; \dots]$. It is defined as follows:
%
%\begin{small}
\begin{align*}
\mU_{\rk}(\rk, \rk) =&\, [] \\
\mU_{\rk}(\effvar, \rk) = \mU_{\rk}(\rk, \effvar) =
%					&\, [\effvar \mapsto  \effrec{\effvar'}{\rk[\effvar \leftarrow \effvar']} ]  \text{ if } \mathtt{occur\_check}(\effvar, \rk) \\
					&\, [\effvar \mapsto  \effrec{\effvar}{\rk} ]  \text{ if } \mathtt{occur\_check}(\effvar, \rk) \\
					= &\,  [\effvar \mapsto \rk] \\
\mU_{\rk}(\effor{\rk_1}{\effvar_1}, \effor{\rk_2}{\effvar_2}) =&\,
                  [\effvar_1 \mapsto \effor{\rk_2}{\effvar};  \effvar_1 \mapsto \effor{\rk_1}{\effvar} ]  \text{, } \fresh{\effvar} \\
\mU_{\rk}(\effrec{\effvar'_1}{\effor{\rk_1}{\effvar_1}}, \rk_2) 
    = &\, \mU_{\rk}(\rk_2, \effrec{\effvar'_1}{\effor{\rk_1}{\effvar_1}}) \\ 
    = &\, \mlet K_1 = \effrec{\effvar'_1}{\effor{\rk_1}{\effvar_1}} \\
    &\, \mIn\, \mU_{\rk}( \effor{\rk_1[\effvar'_1 \leftarrow K_1]}{\effvar_1} , \rk_2) \\
%\mU_{\rk}(\effrec{\effvar'_1}{\effor{\rk_1}{\effvar_1}}, \effor{\rk_2}{\effvar_2} ) = 
%    &\, \mlet K_1 = \effrec{\effvar'_1}{\effor{\rk_1}{\effvar_1}} \\
%    &\, \mIn [ \effvar_1 \mapsto \effor{\rk_2}{\effvar} ;  \quad \fresh{\effvar} \\
%     & \quad\;\;                 \effvar_2 \mapsto \effor{\rk_1[\effvar'_1 \leftarrow K_1]}{\effvar}] \\
%\mU_{\rk}(\effrec{\effvar'_1}{\effor{\rk_1}{\effvar_1}}, 
%                 \effrec{\effvar'_2}{\effor{\rk_2}{\effvar_2}} ) = 
%         &\, \mlet K_1 = \effrec{\effvar'_1}{\effor{\rk_1}{\effvar_1}} \\
%         &\, \mand K_2 = \effrec{\effvar'_2}{\effor{\rk_2}{\effvar_2}} \\
%         &\, \mIn [   \effvar_1 \mapsto \effor{\rk_2[\effvar'_2 \leftarrow K_2]}{\effvar} ; 
%                                       \quad \fresh{\effvar} \\
%         & \quad\;\; \effvar_2 \mapsto \effor{\rk_1[\effvar'_1 \leftarrow K_1]}{\effvar} ] \\
%\mU_{\rk}(\rk_1, \rk_2) =&\, \fail{} \qquad\text{otherwise}
\end{align*}
%\end{small}
%
It should be noted that unification never fails, so that we obtain a conservative extension of \rml type system. This unification algorithm also reuse traditional techniques for handling recursive types~\cite{Huet:1975}. The last case unfolds a recursive row to reveal the row variable, so that it can be unified with other rows. 

A downside of our approach is that it introduces one behavior variable for each process, so that the computed behaviors may get very big and unreadable. The purpose of the \textsc{Mask} rule is to remedy this, by using \emph{effect masking}~\cite{Lucassen:1988}. The idea is that if a behavior variable appearing in the behavior is free in the environment, it is not constrained so we can give it any value. In particular, we choose to replace it with $\effplus$, which is the neutral element of $+$, so that it can be simplified away.


\section{Proof of soundness}
\label{sec:soundness}

\input{big_step}

We will now prove the soundness of our analysis, that is, that a well-typed program is reactive. The intuition of the proof is that the first instant of a reactive behavior (as defined in Section~\ref{sec:reactive_behavior}) is a finite behavior, without any recursion. We then prove by induction on the size of behaviors that a well-typed program admits a finite derivation in the big-step semantics.

\subsection{First instant of a behavior}

\begin{definition}
The \emph{first-instant} of a behavior, denoted $\rkfst{\rk}$ is the part of the behavior that corresponds to the execution of the first instant of the corresponding process. It is formally defined by:
\begin{align*}
\rkfst{\effmin} =&\, \rkfst{\effplus}  = \effmin \\
\rkfst{\effvar} =&\, \effvar \\
\rkfst{\effrun{\rk}} =&\, \effrun{(\rkfst{\rk})} \\ 
\rkfst{\effpar{\rk_1}{\rk_2}} =&\, \effpar{\rkfst{\rk_1}}{\rkfst{\rk_2}} \\
\rkfst{\effor{\rk_1}{\rk_2}} =&\, \effor{\rkfst{\rk_1}}{\rkfst{\rk_2}} \\
\rkfst{\effcon{\rk_1}{\rk_2}} =&\, 
		\left\{ \begin{array}{ll}  
				\rkfst{\rk_1} & \text{if } \noinst{\rk_1} \\
				\effcon{\rkfst{\rk_1}}{\rkfst{\rk_2}} &\text{otherwise} 
		\end{array}\right. \\
\rkfst{\effrec{\effvar}{\rk}} =&\, \rkfst{\rk[\effvar \leftarrow \effrec{\effvar}{\rk}]}
\end{align*}
\end{definition}
In the case of a recursive behavior,  the first-instant behavior is well-defined only if the behavior is reactive, that is, the recursion is not instantaneous.

%\todo{Ne le definir que pour comportement ferme ?}
\begin{definition}
A behavior is \emph{finite}, denoted $\rkfinite{\rk}$, if it does not contain any true recursive behavior. The finite behaviors $\rkf$ are defined by: 
%\begin{mathpar}
%\inferrule{ }{\rkfinite{\effmin}}
%\and
%\inferrule{ }{\rkfinite{\effplus}}
%\and
%\inferrule{ }{\rkfinite{\effvar}}
%\and
%\inferrule{ \rkfinite{\rk_1} \\ \rkfinite{\rk_2} }{ \rkfinite{\effpar{\rk_1}{\rk_2}}  }
%\and
%\inferrule{ \rkfinite{\rk_1} \\ \rkfinite{\rk_2} }{ \rkfinite{\effor{\rk_1}{\rk_2}}  }
%\and
%\inferrule{ \rkfinite{\rk_1} \\ \rkfinite{\rk_2} }{ \rkfinite{\effcon{\rk_1}{\rk_2}}  }
%\and
%\inferrule{ \rkfinite{\rk} \\ \effvar \not\in \fbv{\rk} }{ \rkfinite{\effrec{\effvar}{\rk} } }
%\and
%\inferrule{ \rkfinite{\rk} }{ \rkfinite{\effrun{\rk} } }
%\end{mathpar}
\[
\rkf \sdeq \effplus \mid \effmin \mid \effvar \mid \effpar{\rkf}{\rkf} \mid \effor{\rkf}{\rkf}
\mid \effcon{\rkf}{\rkf}  \mid \effrun{\rkf}
\]
\end{definition}

We can now express the important property of reactive behaviors, that is, the first instant of a reactive behavior is finite.
\begin{property}
If $\rk$ is  reactive, then $\rkfst{\rk}$ is a finite behavior, i.e.:
\[ \wf{\emptyset}{\rk} \ \Rightarrow\  \rkfinite{\rkfst{\rk}} \]
\end{property}
\begin{proof}
By induction on the structure of behaviors.
\end{proof}

\subsection{Big-step Semantics}
\label{sec:semantics}

In this section, we give an overview of the big-step semantics of \rml{}, also called the behavioral semantics in reference to the one of \esterel~\cite{Berry:1996} from which it is inspired. The interested reader can refer to~\cite{Mandel:2005} for a more detailed presentation of this semantics.

The reaction of an expression is defined by the smallest signal environment $S_i$ such that:
\[ \bigstep{N}{e_i}{e_{i+1}}{E_i}{b_i}{S_i} \]
which means that during the instant, in the signal environment $S_i$, the expression~$e_i$ rewrites to~$e_{i+1}$ and emits the signals in $E_i$. $b_i$ is a boolean that indicates if $e_{i+1}$ has terminated. Additional conditions express for instance the fact that the emitted values in $E_i$ must agree with the signal environment $S_i$. The execution of a program is made of the succession of a (potentially infinite) number of reactions and terminates when the status $b_i$ is equal to true.
%
 We refer the reader to~\cite{Mandel:2005} or Appendix~\ref{sec:big_step_other} for a more formal presentation, including the definition of the signal environment $S$. We just write $n \in S$ when the signal $n$ is present in the signal environment $S$ (i.e. it has been emitted in the current instant) and $n \not\in S$ otherwise.


Figure~\ref{fig:big_step} shows part of the rules defining the relation. The remaining rules can be found in Appendix~\ref{sec:big_step_other}. 
\begin{itemize}
\item  The rule for $\epause{}$ shows the meaning of the boolean $b$: if it is false, it means that the expression is stuck waiting for the next instant.
\item The $\mathtt{let}/\mathtt{and}$ construct executes its two branches until both are terminated.
\item The $\mathtt{present}$ construct executes the $\mathtt{then}$ branch immediately if the signal is present, but it executes the $\mathtt{else}$ branch on the next instant if it is absent.
\item The $\mathtt{do/when}$ construct executes its body only if the signal $n$ is present. If the body terminates, that is, it rewrites to a value $v$, then the construct also terminates instantaneously and rewrites to the same value.
\item The unconditional loop keeps executing its body until it awaits the next instant, that is, its termination status $b$ becomes false. In particular, an expression like $\eloop{\evoid{}}$, where the body always terminates instantaneously, does not have a semantics as it would require an infinite derivation tree.
\end{itemize}


\subsection{Soundness}

As we said earlier, we do not try to prove that functions terminate and only care about processes. We suppose that all functions terminate, which is reflected in the rule for application (Figure~\ref{fig:rules}) by the fact that the behavior of the application is always the instantaneous behavior $\effmin$. This hypothesis is made possible by the syntactic distinction between functions and processes. Before going further with the proof of soundness, we have to express this hypothesis more formally with respect to the big-step semantics.

\begin{hypothesis}[Function calls always terminate]
\label{hyp:fun_terminate} 
For any ML expression $e$, i.e. such that $0 \vdash e$ (defined in \cite{Mandel:2005}), there exists a finite derivation $\Pi$ and a value $v$ such that:
\[ \inferrule{\Pi}{ \quad \bigstep{N}{e}{v} {E}{b}{S} \quad } \] 
\end{hypothesis}

We first need to prove the soundness of our definition of non-instantaneous behavior, as expressed in the following lemma:
\begin{lemma}
\label{lem:noinst}
An expression whose behavior is not instantaneous never reduces instantaneously.
\[
\left( \tyju{\tyenv}{e}{\rt}{\rk}
 \ \land\  \noinst{\rk} \ \land\  \bigstep{N}{e}{e'} {E}{b}{S}  \right) \ \Rightarrow\  b = \sfalse \]
\end{lemma}
\begin{proof}
By induction on the derivation of the big-step semantics.
\end{proof}

We can now express the soundness of our analysis, that is, a well-typed program is reactive. Being reactive means here that there exists a derivation, necessarily finite, to rewrite the program into a well-typed program.
\begin{theorem}[Soundness]
\label{thm:soundness}
If \mbox{$\tyju{\tyenv}{e}{\rt}{\rk}$} and $\rt$ and $\rk$ are reactive and we suppose that function calls terminate, then there exists $e'$ such that \mbox{$\bigstep{N}{e}{e'} {E}{b}{S}$} and \mbox{$\tyju{\tyenv}{e'}{\rt}{\rk'}$} with $\rk'$ reactive.
\end{theorem}
\begin{proof}
The proof is done by induction on the size of the first-instant behavior of well-typed expressions. The main point is that the behaviors of sub-expressions is always smaller, but we have to be careful that we must consider only the first-instant behavior. To prove that the result is well-typed, we can use classic syntactic techniques for type soundness~\cite{Pierce:2002} on the small-step semantics described in~\cite{Mandel:2005}. The proof of equivalence of the two semantics is also given in the same paper.
%
%\todo{Corriger les notations dans les regles et ici pour les accorder}
\begin{itemize}
\item Case $\eapp{e_1}{e_2}$ and $\erec{x}{e}$: By Hypothesis~\ref{hyp:fun_terminate}.

\item Case $\erun{e}$: We know that $0 \vdash e$ so there exists $\Pi$ such that 
\[ \inferrule{\Pi}{ \bigstep{N_1}{e}{\eproc{e_1}} {E}{\strue}{S} } \]
Then, as $\erun{e}$ is well-typed, we have that:
\[
\inferrule
  {
  \inferrule
    { \tyju{\tyenv}{e_1} {\rt}{\rk}  }
    { \tyju{\tyenv}{\eproc{e_1}} { \rtproc{\rt}{\effor{\rk}{\rk'}} }{\effmin} }
  }
  { \tyju{\tyenv}{\erun{(\eproc{e_1})}} {\rt}{\effrun{(\effor{\rk}{\rk'})}} }
\]
We can apply the induction hypothesis as the first-instant behavior of $e_1$, i.e. $\rkfst{\rk}$, is smaller than the first-instant behavior of $\erun{e}$. Indeed, we have:
\[ \rkfst{\effrun{(\effor{\rk}{\rk'})}} = \effor{\effrun{(\rkfst{\rk})}}{\effrun{(\rkfst{\rk'})}} \]

The induction hypothesis allows to conclude that:
\[  \inferrule{\Pi_1}{ \bigstep{N_2}{e_1}{e'_1} {E_1}{b}{S} } \]
which enables us to build the complete derivation of $\erun{e}$:
\[
\inferrule
{
\inferrule{\Pi}{ \bigstep{N_1}{e}{\eproc{e_1}} {E}{\strue}{S} } \\
\inferrule{\Pi_1}{ \bigstep{N_2}{e_1}{e'_1} {E_1}{b}{S} }
}
{ \bigstep{N_1 \cdotp N_2}{\erun{e}}{e'_1} {E \sqcup E_1}{b}{S} }
\]

\item Case $\epause{}$: The derivation is already finite without any hypothesis.

\item Case $\epres{e}{e_1}{e_2}$: 
Like in the first case, we have:
\[ \inferrule{\Pi}{ \bigstep{N_1}{e}{n} {E}{\strue}{S} } \]
The typing rule is as follows:
\[ 
\inferrule%[Present]
  { \tyju{\tyenv}{e}{\rtsig{\rt_1}{\rt_2}}{\effany} \\
    \tyju{\tyenv}{e_1}{\rt}{\rk_1}  \\
    \tyju{\tyenv}{e_2}{\rt}{\rk_2}  }
  { \tyju{\tyenv} { \epres{e}{e_1}{e_2} }{\rt}{ \effor{\rk_1}{(\effcon{\effplus}{\rk_2})} } }
\]
The are then two cases depending on the status of $n$:
\begin{itemize}
\item If \mbox{$n \in S$}: We can notice that \[ \rkfst{\effor{\rk_1}{(\effcon{\effplus}{\rk_2})}} = \effor{\rkfst{\rk_1}}{\effmin} \] so we can apply the induction hypothesis on the first-instant behavior of $e_1$ and conclude. 
\item If $n \not\in S$: The derivation is finite.
\end{itemize}

\item Case $\ewhen{e_1}{e_2}$: We can use the same reasoning. It is interesting to note that the behavior associated to the expression, i.e. $\effor{\rk}{\effinf{\effplus}}$, is not equal to the behavior of the body, as one could expect, so that we can apply the induction hypothesis.

\item Case $\eletpar{x_1}{e_1}{x_2}{e_2}{e}$:
When we compute the first instant of a sequence, there are two possible cases:
\begin{itemize}
\item If $\noinst{(\effpar{\rk_1}{\rk_2})}$, then we have that 
\[  \rkfst{\rk} = \effpar{\rkfst{\rk_1}}{\rkfst{\rk_2}} \]
From $\noinst{(\effpar{\rk_1}{\rk_2})}$, we get that either $\noinst{\rk_1}$ which implies that $b_1 = \sfalse$, or $\noinst{\rk_2}$ which implies that $b_2 = \sfalse$ using Lemma~\ref{lem:noinst}. So we are sure that $b_1 \land b_2 = \sfalse$. We can then apply the induction hypothesis on $e_1$ and $e_2$ using the rule~\textsc{Let-Par}.

\item Otherwise, we have that
\[  \rkfst{\rk} = \effcon{(\effpar{\rkfst{\rk_1}}{\rkfst{\rk_2}})}{\rkfst{\rk_3}} \]
We can apply the induction hypothesis on $e_1$, $e_2$ and $e_3$ using either \textsc{Let-par} or \textsc{Let-Done} depending on the values of $b_1$ and $b_2$.
\end{itemize}

\item Case $\eloop{e}$: 
We have that \mbox{$\rkfst{(\effcon{\effmin}{\rk})} = \effcon{\effmin}{\rkfst{\rk}}$}, so we can apply the induction hypothesis on $e$.
As the behavior $\effinf{(\effcon{\effmin}{\rk})}$ is reactive, we know that $\noinst{\rk}$. By applying Lemma~\ref{lem:noinst}, we get that $b = \sfalse$, so we reconstruct the complete derivation for $e$ using the \textsc{Loop-Stuck} rule.

\end{itemize}

\end{proof}

\section{Discussion}
\label{sec:discussion}

\subsection{Simplifying behaviors}

The behaviors computed by the type system of Section~\ref{sec:type_system} are very big. For instance, the behavior associated to the `timer` example is 
\[ \effinf{(\effcon{(\effpar{\effmin}{\effmin})}{(\effor{\effmin}{(\effcon{\effmin}{\effmin})})})} \] 
This behavior is unnecessarily detailed and almost as big (if not bigger) than the source program. However, we can notice that this behavior is equivalent to $\effinf{\effmin}$.

We would like to use this equivalence relation on behaviors defined in Section~\ref{sec:equiv_behaviors} in our type system to reduce the size of the computed behaviors. We must  make sure that this does not break the proof of soundness of Section~\ref{sec:soundness}. This is ensured by the fact that the equivalence relation preserves reactivity (Property~\ref{prop:equiv_reactivty}), which is the only condition requested by the proof.

We can thus define a variant of the type system, which is the one implemented in the compiler, with a new typing judgment $\tyjus{\tyenv}{e}{\rt}{\rk}$. It is defined by the rules given in Figure~\ref{fig:rules} with one additional rule, that allows to simplify behaviors at any time using the equivalence relation:
\[
\rulename{Equiv}
\inferrule
  { \tyjus{\tyenv}{e}{\rt}{\rk_1} \\ \effeq{\rk_1}{\rk_2} }
  { \tyjus{\tyenv}{e}{\rt}{\rk_2} } 
\]
We cannot add this rule to the original system as the proof of soundness relies on the fact that the behavior of sub-expressions is always smaller, which is no longer the case once we allow simplifications. We can also simplify some rules, by combining the original rule with the \textsc{Equiv} rule:
\begin{mathpar}
%
\inferrule%*[Left=(Signal)]
  { \tyjus{\tyenv}{e_1}{\rt_2}{\effany}  \\ 
    \tyjus{\tyenv}{e_2}{ \rtarrow{\rt_1}{\rtarrow{\rt_2}{\rt_2}} }{\effany} \\\\
    \tyjus{\tyenv \tyconcat x : \rtsig{\rt_1}{\rt_2}} {e} {\rt}{\rk}  }
  { \tyjus{\tyenv}{ \esig{x}{e_1}{e_2}{e} } {\rt}{ \rk} }
%
\and
%
\inferrule%[When]
  { \tyjus{\tyenv}{e_1}{\rt}{\rk} \\\\
    \tyjus{\tyenv}{e_2}{\rtsig{\rt_1}{\rt_2}}{\effany} }
  { \tyjus{\tyenv}{ \ewhen{e_1}{e_2} } {\rt} {\rk} } 
%
\and
%
\inferrule%[Loop]
  { \tyjus{\tyenv}{e}{\rt}{\rk} }
  { \tyjus{\tyenv}{\eloop{e}}{\unit}{\effinf{\rk}} }
%
\end{mathpar}

The \textsc{Equiv} rule does not change the fact that a program is accepted or rejected by the type system. It only allows to reduce the size of computed behaviors:
\begin{property}
\label{prop:variant_system}
If $\tyjus{\tyenv}{e}{\rt}{\rk}$, then $\tyju{\tyenv}{e}{\rt'}{\rk'}$ with $\effeq{\rk}{\rk'}$ and $\tyeq{\rt}{\rt'}$.
\end{property}
\begin{proof}
Straightforward by induction on the typing rules
\end{proof}

We can then express the soundness theorem in terms of the variant of the type system:
\begin{theorem}[Soundness (variant)]
If \mbox{$\tyjus{\tyenv}{e}{\rt}{\rk}$} and $\rt$ and $\rk$ are reactive and we suppose that function calls terminate, then there exists $e'$ such that \mbox{$\bigstep{N}{e}{e'} {E}{b}{S}$} and \mbox{$\tyjus{\tyenv}{e'}{\rt}{\rk'}$} with $\rk'$ reactive.
\end{theorem}
\begin{proof}
By applying Property~\ref{prop:variant_system}, Property~\ref{prop:equiv_reactivty} and Theorem~\ref{thm:soundness}.
\end{proof}

\subsection{The \texttt{run} operator}
\label{sec:run}

So far, we have not justified the presence of the $\mathtt{run}$ operator in the language of behaviors. It is here to ensure that, even when adding simplification to the type system, the behavior associated to a recursive process is always a recursive behavior, that is, $\effrec{\effvar}{\rk}$ with $\effvar \in \fbv{\rk}$. 

Suppose that we remove the $\mathtt{run}$ operator from the language of behaviors. Now, consider the process  $\erec{p}{\eproc{(\erun{p})}}$. In the variant of the type system, we could give it the instantaneous behavior $\effmin$ and miss the instantaneous recursion:
%
\[
\inferrule
{
\inferrule
  {
     \inferrule*[left=Equiv]
     {
     \inferrule*
      { \tyjus{\tyenv'}{p}{\rtproc{\beta}{\effor{\effmin}{\effplus}}}{\effmin} }
      { \tyjus{\tyenv'}{\erun{p}} {\beta}{\effor{\effmin}{\effplus}} }
      \\
      \effeq{\effor{\effmin}{\effplus}}{\effmin}
     }
     {
     \tyjus{\tyenv'}{\erun{p}} {\beta}{\effmin}
     }
%        \qquad \boxed{\rtvar = \rtproc{\beta}{\rk}}  
  }  
  { \tyjus{\tyenv'}{\eproc{(\erun{p})}} 
                     {\rtproc{\beta}{\effor{\effmin}{\effplus}}}{\effmin} }
}
{ \tyjus{\tyenv}{ \erec{p}{\eproc{(\erun{p})}} }{\rtproc{\beta}{\effmin}}{\effmin} }
%\qquad \boxed{\rtvar = \rtproc{\beta}{\rk}}  
\]
%
where $\tyenv' = \tyenv \tyconcat p : \rtproc{\beta}{\effor{\effmin}{\effplus}}$.
%
Thanks to the addition of $\mathtt{run}$, the only way to type this process is to give it the behavior $\effrec{\effvar}{(\effor{\effrun{\effvar}}{\rk'})}$ (where $\rk'$ is not constrained). This also explains why there is no equivalence rule to simplify a $\mathtt{run}$. For instance, $\effrun{\effmin}$ is not equivalent to $\effmin$.

%The typing derivation shows that we must have \mbox{$\effor{\effrun{\rk}}{\rk'} = \rk$} to type this expression. The only behavior that verifies this equation is \mbox{$\rk = \effrec{\effvar}{\effor{\effrun{\effvar}}{\rk'}}$} ($\rk'$ is unconstrained here). Without $\mathtt{run}$, the typing derivation would be valid for any behavior $\rk$, for instance $\rk = \effmin$. It means that our analysis would have accepted this process even though it is obviously non-reactive. 



\subsection{Implementation}

The type inference algorithm of \rml has been extended to compute the behaviors of processes, with a small impact on its structure and complexity thanks to the use of row polymorphism for subeffecting (see Section~\ref{sec:subeffecting_row}). The rules given in Section~\ref{sec:reactive_behavior} are easily translated into an algorithm for checking the reactivity of behaviors, polynomial in the size of behaviors. Inference simplifies behaviors during the computation, but does not necessarily compute the smallest behavior possible. For instance, simplifying $\effor{\rk}{\rk}$ can be costly in some cases, so it only checks simple cases (e.g. if $\rk = \effmin$ or $\rk = \effplus$). Overall, the analysis has a small impact on the compilation time of \rml programs.


\subsection{Examples}
%
%The behavior computed for the `timer` example of Section~\ref{sec:first_example} is \mbox{$\effinf{(\effcon{(\effpar{\effmin}{\effmin})}{(\effor{\effmin}{(\effcon{\effmin}{\effmin})})})}$}, which is equivalent to $\effinf{\effmin}$ and not reactive. After the fix, the behavior becomes \mbox{$\effinf{(\effcon{(\effpar{\effmin}{\effmin})}{\effcon{(\effor{\effmin}{(\effcon{\effmin}{\effmin})})}{\effplus}})}$} (equivalent to $\effinf{\effplus}$), which is now reactive. Similarly, the `instantaneous` process defined in Section~\ref{sec:intuition} has a behavior equal to $\effrec{\effvar}{\effcon{\effmin}{\effrun{\effvar}}}$, that is obviously non reactive.

Using a type-based analysis makes it easy to deal with cases of aliasing, like in the following example:
\begin{lstlisting}
let rec process p =
  let q = (fun x -> x) p in
  run q 
?val p : 'a process[rec 'r. (run 'r + ..)]?
?W: This expression may produce an instantaneous recursion?
\end{lstlisting}
`q` has the same type as `p`, and thus the same behavior, so the instantaneous recursion is easily detected. As for objects in \ocaml~\cite{Vouillon:2008}, row variables that appear only once are printed \verb+`..'+.

The analysis can also handle combinators. For instance, the type system computes the following behavior for the `par_comb` example of Section~\ref{sec:intuition}:
\begin{lstlisting}
let process par_comb q1 q2 =
  loop
    run q1 || run q2
  end
?val par_comb : 'a process['r1] -> 'b process ['r2] ->
 unit process[rec 'r3. ((run 'r1 || run 'r2); 'r3 + ..)]?
\end{lstlisting}
%
There is no warning when defining the combinator because it is not possible to decide of its reactivity. Indeed, the synchronous parallel composition terminates when both branches have terminated. It means that the loop is non-instantaneous if either `q1` or `q2` is non-instantaneous. Formally, the computed behavior is reactive because free behavior variables are considered to be non-instantaneous (see Definition~\ref{def:reactive_behavior}). The reactivity is then checked at the instantiation. If we instantiate the `par_comb` combinator with two anonymous processes, one instantaneous and the other non-instantaneous, then we obtain a process that is indeed reactive, so no warning is printed:
\begin{lstlisting}
let process p1 = 
  run (par_comb (process ()) (process (pause)))
?val p1: unit process[run(rec 'r.(run 0 || run *);'r)+..]?
\end{lstlisting}
However, if the two processes are instantaneous, then the loop becomes instantaneous. The behavior that results is obviously non-reactive, so a warning is shown:
\begin{lstlisting}
let process p2 = 
  run (par_comb (process ()) (process ()))
?val p2: unit process[run(rec 'r.(run 0||run 0);'r) + ..)]
W: This expression may produce an instantaneous recursion?
\end{lstlisting}

Here is another more complex example using higher-order functions and processes. We define a function `h_o` that takes as input a combinator `f`. It then creates a recursive process that applies `f` on itself and runs the result:
\begin{lstlisting}
let h_o f =
 let rec process p =
   let q = f p in
   run q
 in p
?val h_o : ('a process[run 'r1 + 'r2] -> 'a process['r1]) 
                -> 'a process[run 'r1 + 'r2]?
\end{lstlisting}
If we instantiate this function with a process that waits an instant before calling its argument, we obtain a reactive process:
\begin{lstlisting}
let process good = 
  run (h_o (fun x -> process (pause; run x)))
?val good :
 'a process[run (run (rec 'r1. *; run (run 'r1))) + ..]?
\end{lstlisting}
This is no longer the case if the process calls its argument instantaneously. The instantaneous recursion is again detected by the analysis:
\begin{lstlisting}
let process pb = 
  run (h_o (fun x -> process (run x)))
?val pb : 
     'a process[run (run (rec 'r1. run (run 'r1))) + ..]
W: This expression may produce an instantaneous recursion?
\end{lstlisting}

Another interesting process that can be analyzed is a fix-point operator. It takes as input a function expecting a continuation, and applies it with itself as the continuation. This fix-point operator can be used to create a recursive process, which reactivity is checked by our analysis:
\begin{lstlisting}
let rec fix f x = f (fix f) x
?val fix : (('a -> 'b) -> 'a -> 'b) -> 'a -> 'b?

let process main =
  let process p k v =
    print_int v; print_newline (); 
    run (k (v+1))
  in
  run (fix p 0)
?val main : 'a process[(run (rec 'r. run 'r)) + ..]
W: This expression may produce an instantaneous recursion?
\end{lstlisting}

\subsection{Adding references}

References are not included in the kernel of our language. However, they are relevant to the matter as they can be used to encode recursivity, as in the following example that creates a process that loops instantaneously:
%
\begin{lstlisting}
let landin () =
  let f = ref (process ()) in
  f := process (run !f);
  !f
?val landin : unit -> 
        unit process[0 + (rec 'r1. run (0 + 'r1)) + ..]?
?W: This expression may produce an instantaneous recursion?
\end{lstlisting}
%
%?val landin : unit -> 
%        unit process[$\effor{\effor{\effmin}{\effrec{\effvar
%                         }{\effrun{(\effor{\effmin}{\effvar})}}}}{\effvar'}$] ?
As our analysis does not have any special case for recursive processes and only relies on unification, it is able to detect the reactivity issue even though there is no explicit recursion.

\section{Related work}
\label{sec:related_work}


Our language of behaviors and type system is inspired by the work of~\cite{Amtoft:1999}. Their analysis is done on the \cml~\cite{Reppy:2007} language, which extends ML with message passing primitives. The behavior of a process records every emission and reception on communication channels. The authors use the type system to prove properties on particular examples, not for a general analysis. For instance, they prove that the emission on a given channel always precede the emission on a second channel in a given program. The idea to use a type-and-effect system for checking reactivity or termination is not new. \cite{Boudol:2010}~uses a type-and-effect system to prove termination of functional programs using references, by stratifying memory to avoid recursion through references.

Reactivity analysis is a classic topic in synchronous languages, that can also be related to causality. In \esterel~\cite{Berry:1997}, the first imperative synchronous language, it is possible to react immediately to the presence \emph{and} the absence of a signal. The consequence is that a program can be non-reactive because there is no consistent status for a given signal: the program supposes that a signal is both present and absent during the same instant. This problem is solved by checking that programs are \emph{constructively correct}~\cite{Berry:1996}. Our concurrency model, inherited from~\cite{Boussinot:1991}, avoids these problems by making sure that processes are causal by construction. We then only have to check that loops are not instantaneous,what is called \emph{loop-safe} in \cite{Berry:1996}.  It is easy to check that an \esterel program is loop-safe as the language is first order without recursion. 
%Reactivity analysis is a classic topic in synchronous languages. In \esterel~\cite{Berry:1997}, the first imperative synchronous language, reactivity .

Closer to \rml, the reactivity analysis of \funloft~\cite{Amadio:2007b} not only checks that instants terminate, but also give a bound on the duration of the instants trough a value analysis. The analysis is also restricted to the first-order setting. In \ulm~\cite{Boudol:2004}, each recursive call induces an implicit pause. Hence, it is impossible to have instantaneous recursions, at the expense of expressivity. For instance, in the `server` example of Section~\ref{sec:intuition}, a message could be lost between receiving a message on `add` and awaiting a new message.

The causality analysis of \lucy~\cite{Cuoq:2001} is a type-and-effect system using row types. It is based on the exception analysis done in~\cite{Leroy:2000}. Both are a more direct application of row types~\cite{Remy:1993}, whereas our system differs in the absence of labels in rows.

\todo{These de Gimenez}

\section{Conclusion}

We have presented a reactivity analysis on the \rml language. The idea of the analysis is to abstract processes into a simpler language called behaviors using a type-and-effect system. Checking reactivity of behaviors is then straightforward. We have proven the soundness of our analysis, that is, a well-typed program is reactive. Thanks in particular to the syntactic separation between functions and processes, the analysis does not detect too much false positives in practice and has been proven very useful for avoiding reactivity bugs. 

We believe this work could be applied to other models of concurrency. One just need to give the behavior $\effplus$ to operations that cooperate with the scheduler, like \texttt{yield}.

An important direction for future work is to study the properties of our type system. In particular, it would be interesting to compare our approach to subeffecting using row polymorphism with traditional solutions and see if it could be applied in a different setting.
%
%Important hypothesis: separate functions from processes. Only check reactivity of processes
%
%Future work: meta-theory of type system (principality, etc). Comparison with other subeffecting formulations

\bibliographystyle{plain}

\begin{small}
\bibliography{biblio}
\end{small}

%\clearpage


\appendix

%\begin{figure*}
%\begin{align*}
%&E = E_1 \sqcup E_2 \text{ iff } \forall n \in \mathit{Dom}(E_1) \cup \mathit{Dom}(E_2).\, 
%    E(n) = E_1(n) \uplus E_2(n) \\
%&E_1 \sqsubseteq E_2 \text{ iff } \forall n \in \mathit{Dom}(E_1).\, E_1(n) \subseteq E_2(n) \\
%&S_1 \sqsubseteq S_2 \text{ iff } S^m_1 \sqsubseteq S^m_2 \\
%&(S + [v/n])(n') = \left\{ 
%  \begin{array}{ll}
%    S(n') & \text{if } n' \neq n \\
%    (S^d(n), S^g(n), S^m(n) \uplus \{v\}) & \text{if } n' = n
%  \end{array}
% \right.
%\end{align*}
%
%\caption{Operations on signal environments and events}
%\label{fig:events_op}
%\end{figure*}

\begin{figure*}[t]
%\begin{small}
\input{big_step_other}
%\end{small}

\caption{Remaining rules for the big-step semantics}
\label{fig:big_step_other}
\end{figure*}

\todo{Parler de la preuve des expressions ajout√©es dans cette section}

\section{Big-step semantics (continued)}
\label{sec:big_step_other}

\todo{Rappeler la definition de la bonne formation des expressions}

\subsection{Notations}

\subsubsection*{Signal environment}

%Let $\mathcal{N}$ be a numerable set of signal names $n$. We denote $N_i$ subsets of $\mathcal{N}$. $N_1 \cdotp N_2$ is the disjoint union of the two sets and is only defined if $N_1 \cap N_2 = \emptyset$.
 A \emph{signal environment} $S$ is a function
\[ S \deq [ (d_1, g_1, m_1)/n_1, \dots, (d_k, g_k, m_k)/n_k ] \] 
that maps a signal name $n_i$ to a tuple $(d_i, g_i, m_i)$ where $d_i$ is the default value of the signal, $g_i$ its combination function and $m_i$ is the multi-set of values emitted during the reaction. If the signal $n_i$ has the type $\rtsig{\rt_1}{\rt_2}$, then these fields have the following types:
\begin{mathpar}
d_i : \rt_2
\and
g_i : \rtarrow{\rt_1}{\rtarrow{\rt_2}{\rt_2}}
\and
m_i : \rt_2 \mathid{multiset}
\end{mathpar}
We denote $S^d(n_i) = d_i$, $S^g(n_i) = g_i$ and $S^m(n_i) = m_i$. We also define $S^v(n_i) = \mathit{fold}\; g_i\; m_i\; d_i$ where:
\begin{align*}
\mathit{fold}\; f\; (\{ v_1 \} \uplus m)\; v_2 &= \mathit{fold}\; f\; m\; (f v_1 v_2) \\
\mathit{fold}\; f\; \emptyset\; v_2 &= v
\end{align*}
We denote $n \in S$ when the signal $n$ is present, that is, when $S^m(n) \neq \emptyset$, and $n \not\in S$ otherwise.

\subsubsection*{Events}

An \emph{event} $E$ is a function mapping a signal name to a multi-set of values:
\[ E \deq [ m_1/n_1, \dots, m_k/n_k] \]
Events represent the values emitted during an instant. $S^m$ is the event associated to the signal environment $S$.

\subsection*{Operations on signal environments and events}

The union of events is the point-wise union, that is, if $E = E_1 \sqcup E_2$, then for all  $n \in \mathit{Dom}(E_1) \cup \mathit{Dom}(E_2)$: 
\[ E(n) = E_1(n) \uplus E_2(n) \]
Similarly, the inclusion of events is the point-wise inclusion. We define the inclusion of signal environments by:
\[ S_1 \sqsubseteq S_2 \text{ iff } S^m_1 \sqsubseteq S^m_2 \\ \]

%We define several operations on signal environments and events in Figure~\ref{fig:events_op}. %In particular, the operation $S + [v/n]$ adds $v$ to the multi-set of values associated to $n$ in $S$.

\subsection{Big-step semantics}

At each instant, the program reads inputs~$I_i$ and produces outputs~$O_i$. The reaction of an expression is defined by the smallest signal environment $S_i$ (for the relation $\sqsubseteq$) such that:
\[ \bigstep{N}{e_i}{e_{i+1}}{E_i}{b_i}{S_i} \]
where
\begin{align}
& (I_i \sqcup E_i ) \sqsubseteq S_i^m \\
& O_i \sqsubseteq E_i \\
%& \forall n \in N_{i+1}.\; n \not\in \mathit{Dom}(S_i) \\
& S^d_i \subseteq S^d_{i+1} \text{ and } S^g_i \subseteq S^g_{i+1} 
\end{align}
\begin{itemize}
\item[(1)] The signal environment must contain the inputs and emitted signals.
\item[(2)] The outputs are included in the set of emitted signals.
%\item[(3)] This properties guarantees that new signal names are fresh.
\item[(3)] Default values and combination functions are kept from one instant to the next.
\end{itemize}

The rules defining the relation are given in Figure~\ref{fig:big_step} and Figure~\ref{fig:big_step_other}:
\begin{itemize}
\item $\eemit{e_1}{e_2}$ evaluates $e_1$ into s signal name $n$ and adds the result of the evaluation of $e_2$ to the multi-set of emitted values on $n$.
\item The declaration of a signal evaluates the default value and combination function, and then evaluates the body after substituting $x$ with a fresh signal name $n$. In this paper, we have kept implicit the sets of signal names that are used to ensure the freshness of this name (see \cite{Mandel:2005} for how to do this).
\item The preemption in \rml is weak, that is, a process can only be preempted at the end of the instant. This is reflected by the fact that $e_1$ is always evaluated, regardless of the status of the signal~$n$. It also means that, when the signal is present, $e_2$ is executed at the next instant.
\end{itemize}

\end{document}
